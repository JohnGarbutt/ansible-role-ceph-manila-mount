---
- name: Allow access to centos user for admin
  lineinfile:
    path: /home/centos/.ssh/authorized_keys
    line: "{{ item }}"
    owner: centos
    group: centos
    mode: 0600
  with_items: "{{ hibd_spark_allowed_ssh_keys_admin }}"

- name: Allow access to hadoop user to submitting jobs
  lineinfile:
    path: /home/hadoop/.ssh/authorized_keys
    line: "{{ item }}"
    owner: hadoop
    group: hadoop
    mode: 0600
  with_items: "{{ hibd_spark_allowed_ssh_keys_user }}"

- name: Add slaves config
  template:
    src: slaves
    dest: "{{ hibd_spark_home }}/conf/slaves"
  notify:
    - Restart Spark

- name: Add spark-env
  template:
    src: spark-env.sh
    dest: "{{ hibd_spark_home }}/conf/spark-env.sh"
  notify:
    - Restart Spark

- name: Add spark-defaults
  template:
    src: spark-defaults.conf
    dest: "{{ hibd_spark_home }}/conf/spark-defaults.conf"
  notify:
    - Restart Spark

- name: Install python3
  package:
    name: python34-pip,python34-virtualenv

- name: Create python3 virtualenv
  shell: 'su {{ hibd_spark_user }} -c "virtualenv-3 {{ hibd_spark_py3_venv }}"'
  args:
    creates: "{{ hibd_spark_py3_venv }}"

- name: Upgrade pip
  shell: 'su {{ hibd_spark_user }} -c "{{ hibd_spark_py3_venv }}/bin/pip install --upgrade pip"'
  args:
    creates: "{{ hibd_spark_py3_venv }}"

- name: Upgrade setuptools
  shell: 'su {{ hibd_spark_user }} -c "{{ hibd_spark_py3_venv }}/bin/pip install --upgrade setuptools"'
  args:
    creates: "{{ hibd_spark_py3_venv }}"

# vlad's testing

- name: All users should see SPARK_HOME
  file:
    src: /opt/spark/conf/spark-env.sh
    dest: /etc/profile.d/spark.sh
    owner: root
    group: root
    state: link

# https://github.com/jeffhung/ansible-sbt/blob/master/tasks/install_from_repositories.yml
#
- name: Install bintray yum repository (ansible < 2.1)
  get_url:
    url:  https://bintray.com/sbt/rpm/rpm
    dest: /etc/yum.repos.d/bintray-sbt.repo

- name: Ensure sbt is installed (yum)
  yum:
    state=present
    name=sbt
